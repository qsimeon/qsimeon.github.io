---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I'm **Quilee Simeon**, a research engineer trained at MIT working at the intersection of **machine learning**, **neuroscience**, and **scientific computing**. I'm currently a PhD candidate in Brain and Cognitive Sciences at MIT, where I combine large-scale data processing, representation learning, and computational modeling to study biological neural circuits.

## üß† Research Focus

My work centers on multimodal neural data modeling, particularly using _C. elegans_ as a platform for understanding how biological neural systems process information. I integrate data across calcium dynamics, connectomics, and transcriptomics using machine learning frameworks including transformer architectures and self-supervised learning.

**Key Research Areas:**
- Multimodal neural data integration and modeling
- Self-supervised learning for neural systems  
- Transformer architectures for time-series neural activity
- Graph-based learning approaches for connectome data
- Neural efficiency and interpretability

## üíº Professional Experience

**Numenta, Inc. ‚Äî Machine Learning Research Intern** (June 2025 ‚Äì September 2025)
- Developed distillation methods for transferring sparsity patterns from large to small models
- Designed sparse weight and activation mechanisms for efficient inference
- Contributed to external collaboration on LLM inference optimization

**MIT Department of Brain and Cognitive Sciences ‚Äî Graduate Researcher** (2022 ‚Äì Present)
- Built large-scale data pipelines for multimodal C. elegans neural datasets
- Modeled neural population dynamics using graph-based architectures
- Integrated transcriptomic and anatomical data for neuron identity prediction

## üõ†Ô∏è Technical Expertise

**Machine Learning & AI:** Transformer models, contrastive learning, spectral normalization, diffusion models, reinforcement learning, neural network interpretability

**Scientific Computing:** Python, PyTorch, Julia, high-performance cluster computing (SLURM-based systems)

**Data Engineering:** Neural data preprocessing, signal aggregation, connectome-based modeling

**Software Tools:** NumPy, PyTorch Geometric, OpenAI API, Hugging Face Datasets, Matplotlib, Marimo/Pluto notebooks

## üéØ Current Direction

I'm transitioning toward applied ML and AI systems roles that blend algorithmic research with scientific applications. I'm particularly interested in:

- Building generalizable models that bridge biological and artificial intelligence
- Working in collaborative environments that value both research depth and practical engineering
- Expanding expertise in reinforcement learning, generative modeling, and distributed systems

I'm open to **Research Engineer**, **Applied Scientist**, or **ML Systems** positions.

## üèÖ Leadership & Community

- **President, IEEE-HKN (Eta Kappa Nu) Honor Society ‚Äî MIT Chapter**
- **Secretary, Fraternity Leadership Role** 
- Mentor and advocate for open science, data transparency, and interdisciplinary education
- Strong commitment to supporting underrepresented minorities in STEM

## üåç Background

I grew up in St. Lucia and completed my B.Sc. in Computation and Cognition (minor in Statistics & Data Science) and a M.Sc. in Brain and Cognition Sciences at MIT, where I'm also curently a PhD candidate. Outside of research, I enjoy reading fiction, hiking, and traveling to understand different cultures.

---

*"I'm driven by the idea that understanding intelligence ‚Äî biological or artificial ‚Äî means learning how information transforms meaningfully through systems."*
